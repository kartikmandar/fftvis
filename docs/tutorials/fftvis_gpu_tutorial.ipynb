{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7221ef1",
   "metadata": {},
   "source": [
    "# Running `fftvis` with the GPU Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce8dc6",
   "metadata": {},
   "source": [
    "In this notebook, we'll demonstrate how to use `fftvis` with GPU acceleration to simulate visibilities. The GPU backend can significantly accelerate simulations, especially for large catalogs of point sources or extended observations with many frequencies and time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0836a520",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "__Note__\n",
    "\n",
    "This tutorial requires a CUDA-capable GPU and the `cupy` package installed. If you don't have a compatible GPU, you can use the CPU backend instead.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d021b5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "__Warning__\n",
    "\n",
    "Before running this tutorial, make sure you have installed `fftvis` with GPU support. You can check if your GPU is properly configured by running a simple test with `cupy`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd48302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy version: 13.4.1\n",
      "CUDA version: 12080\n",
      "Available GPU(s): 1\n",
      "  Device 0: Quadro P600, Memory: 2.08 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "try:\n",
    "    import cupy as cp\n",
    "    print(f\"CuPy version: {cp.__version__}\")\n",
    "    print(f\"CUDA version: {cp.cuda.runtime.runtimeGetVersion()}\")\n",
    "    print(f\"Available GPU(s): {cp.cuda.runtime.getDeviceCount()}\")\n",
    "    for i in range(cp.cuda.runtime.getDeviceCount()):\n",
    "        dev = cp.cuda.Device(i)\n",
    "        props = cp.cuda.runtime.getDeviceProperties(i)\n",
    "        print(f\"  Device {i}: {props['name'].decode()}, Memory: {props['totalGlobalMem']/1e9:.2f} GB\")\n",
    "    gpu_available = True\n",
    "except ImportError:\n",
    "    print(\"CuPy is not installed. Please install it to use the GPU backend.\")\n",
    "    gpu_available = False\n",
    "except cp.cuda.runtime.CUDARuntimeError:\n",
    "    print(\"CUDA runtime error: No CUDA-capable device is detected or CUDA driver is not installed properly.\")\n",
    "    gpu_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac710755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kartikmandar/anaconda3/envs/matvis-env/lib/python3.11/site-packages/pyuvdata/analytic_beam.py:111: UserWarning: basis_vector_type was not defined, defaulting to azimuth and zenith_angle.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "from astropy.time import Time\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# HERA-stack imports\n",
    "import fftvis\n",
    "from hera_sim.antpos import hex_array\n",
    "from pyuvdata.telescopes import Telescope\n",
    "from pyuvdata.analytic_beam import AiryBeam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e479a59",
   "metadata": {},
   "source": [
    "## Setup Telescope / Observation Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cef897",
   "metadata": {},
   "source": [
    "We'll set up the same observation parameters as in the CPU backend tutorial for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9baa4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define antenna array positions\n",
    "antpos = hex_array(3, split_core=True, outriggers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15234c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define antenna beam using pyuvdata.analytic_beam.AiryBeam with a dish size of 14 meters\n",
    "beam = AiryBeam(diameter=14.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0a06a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of frequencies in units of Hz\n",
    "nfreqs = 20\n",
    "freqs = np.linspace(100e6, 120e6, nfreqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42b9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of times with an astropy time.Time object\n",
    "ntimes = 30\n",
    "times = Time(np.linspace(2459845, 2459845.05, ntimes), format='jd', scale='utc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd734be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the telescope location\n",
    "telescope_loc = Telescope.from_known_telescopes('hera').location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0540d40",
   "metadata": {},
   "source": [
    "## Setup Sky Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "866079fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a sky model using HEALPix\n",
    "nside = 64\n",
    "nsource = hp.nside2npix(nside)\n",
    "\n",
    "# Get HEALPix pixel coordinates\n",
    "dec, ra = hp.pix2ang(nside, np.arange(nsource))\n",
    "dec -= np.pi / 2  # Convert from co-latitude to declination\n",
    "\n",
    "# Define the flux of the sources as a function of frequency\n",
    "flux = np.random.uniform(0, 1, nsource)                # flux of each source at 100MHz (in Jy)\n",
    "alpha = np.ones(nsource) * -0.8                        # spectral index of each source\n",
    "\n",
    "# Now get the (Nsource, Nfreq) array of the flux of each source at each frequency\n",
    "flux_allfreq = ((freqs[:, np.newaxis] / freqs[0]) ** alpha.T * flux.T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a45d711",
   "metadata": {},
   "source": [
    "## Run `fftvis` with GPU Backend\n",
    "\n",
    "Unlike the CPU backend which uses `finufft` for non-uniform FFT operations, the GPU backend in `fftvis` uses `cufinufft` through CuPy. This allows for significant speedups, especially with large numbers of sources. \n",
    "\n",
    "To use the GPU backend, we simply specify `backend=\"gpu\"` in the `simulate_vis` function call. All other parameters remain the same as in the CPU version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd21e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subset of baselines we're interested in for simulating\n",
    "baselines = [(i, j) for i in range(len(antpos)) for j in range(len(antpos))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bfb9b0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GPU beam evaluation only supports UVBeam objects with interp method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[0;32m~/fftvis/src/fftvis/wrapper.py:217\u001b[0m, in \u001b[0;36msimulate_vis\u001b[0;34m(ants, fluxes, ra, dec, freqs, times, beam, telescope_loc, baselines, precision, polarized, eps, beam_spline_opts, use_feed, flat_array_tol, interpolation_function, nprocesses, nthreads, coord_method, coord_method_params, force_use_ray, trace_mem, backend)\u001b[0m\n\u001b[1;32m    214\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_simulation_engine(backend\u001b[38;5;241m=\u001b[39mbackend)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Run the simulation\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mants\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfluxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfluxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtelescope_loc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtelescope_loc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolarized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolarized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam_spline_opts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_spline_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_array_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_array_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolation_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnprocesses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnprocesses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoord_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoord_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoord_method_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoord_method_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_use_ray\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_use_ray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrace_mem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_mem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fftvis/src/fftvis/gpu/gpu_simulate.py:286\u001b[0m, in \u001b[0;36mGPUSimulationEngine.simulate\u001b[0;34m(self, ants, freqs, fluxes, beam, ra, dec, times, telescope_loc, baselines, precision, polarized, eps, beam_spline_opts, flat_array_tol, interpolation_function, nprocesses, nthreads, coord_method, coord_method_params, force_use_ray, trace_mem, enable_memory_monitor)\u001b[0m\n\u001b[1;32m    280\u001b[0m nthreads_per_proc \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    282\u001b[0m ] \u001b[38;5;241m*\u001b[39m nprocesses  \u001b[38;5;66;03m# Each GPU process typically uses 1 thread for NUFFT\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nthi, fc, tc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(nthreads_per_proc, freq_chunks, time_chunks):\n\u001b[1;32m    285\u001b[0m     futures\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 286\u001b[0m         \u001b[43mfnc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfreq_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass Ray object ref or direct object\u001b[39;49;00m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoord_mgr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoord_mgr_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass Ray object ref or direct object\u001b[39;49;00m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrotation_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrotation_matrix_gpu_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass Ray object ref or direct object\u001b[39;49;00m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbls_gpu_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass Ray object ref or direct object\u001b[39;49;00m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreqs_gpu_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass Ray object ref or direct object\u001b[39;49;00m\n\u001b[1;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcomplex_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplex_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnfeeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnfeeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpolarized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolarized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeam_spline_opts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_spline_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m            \u001b[49m\u001b[43minterpolation_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnthi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ignored by GPU NUFFT\u001b[39;49;00m\n\u001b[1;32m    301\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_coplanar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_coplanar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrace_mem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_mem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# --- Retrieve Results ---\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_ray:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;66;03m# Ray returns futures, get the results\u001b[39;00m\n",
      "File \u001b[0;32m~/fftvis/src/fftvis/gpu/gpu_simulate.py:457\u001b[0m, in \u001b[0;36mGPUSimulationEngine._evaluate_vis_chunk\u001b[0;34m(self, time_idx, freq_idx, beam, coord_mgr, rotation_matrix, bls, freqs, complex_dtype, nfeeds, polarized, eps, beam_spline_opts, interpolation_function, n_threads, is_coplanar, trace_mem)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# Evaluate beam (on GPU)\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# We need to get the actual scalar value for freq to pass to evaluate_beam\u001b[39;00m\n\u001b[1;32m    454\u001b[0m freq_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    455\u001b[0m     freq\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(freq, cp\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m freq\n\u001b[1;32m    456\u001b[0m )\n\u001b[0;32m--> 457\u001b[0m A_s \u001b[38;5;241m=\u001b[39m \u001b[43mbeam_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_beam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43maz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mza\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolarized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspline_opts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_spline_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolation_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# A_s shape: (nax, nfeed, nsim_sources) or (nsim_sources,)\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Apply flux (on GPU)\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m polarized:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# beam_evaluator.get_apparent_flux_polarized modifies A_s in-place\u001b[39;00m\n",
      "File \u001b[0;32m~/fftvis/src/fftvis/gpu/gpu_beams.py:104\u001b[0m, in \u001b[0;36mGPUBeamEvaluator.evaluate_beam\u001b[0;34m(self, beam, az, za, polarized, freq, check, spline_opts, interpolation_function)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gpu_beam_data[beam_key] \u001b[38;5;241m=\u001b[39m beam_data_gpu\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;66;03m# Non-UVBeam object - not currently supported on GPU\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    105\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU beam evaluation only supports UVBeam objects with interp method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Get cached beam data or use what was just created\u001b[39;00m\n\u001b[1;32m    109\u001b[0m beam_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gpu_beam_data\u001b[38;5;241m.\u001b[39mget(beam_key)\n",
      "\u001b[0;31mValueError\u001b[0m: GPU beam evaluation only supports UVBeam objects with interp method"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Simulate visibilities using the GPU backend\n",
    "if gpu_available:\n",
    "    vis_gpu = fftvis.simulate_vis(\n",
    "        ants=antpos,\n",
    "        fluxes=flux_allfreq,\n",
    "        ra=ra,\n",
    "        dec=dec,\n",
    "        freqs=freqs,\n",
    "        times=times.jd,\n",
    "        telescope_loc=telescope_loc,\n",
    "        beam=beam,\n",
    "        polarized=False,\n",
    "        precision=2,\n",
    "        nprocesses=1,  # Use single process for GPU simulation\n",
    "        baselines=baselines,\n",
    "        backend=\"gpu\"  # Use GPU backend\n",
    "    )\n",
    "else:\n",
    "    print(\"GPU not available. Skipping GPU simulation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9bfea0",
   "metadata": {},
   "source": [
    "## Compare GPU and CPU Backends\n",
    "\n",
    "Let's run the same simulation with the CPU backend for comparison. We expect the results to be nearly identical, with the main difference being the computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da580ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Simulate visibilities using the CPU backend\n",
    "vis_cpu = fftvis.simulate_vis(\n",
    "    ants=antpos,\n",
    "    fluxes=flux_allfreq,\n",
    "    ra=ra,\n",
    "    dec=dec,\n",
    "    freqs=freqs,\n",
    "    times=times.jd,\n",
    "    telescope_loc=telescope_loc,\n",
    "    beam=beam,\n",
    "    polarized=False,\n",
    "    precision=2,\n",
    "    nprocesses=1,\n",
    "    baselines=baselines,\n",
    "    backend=\"cpu\"  # Use CPU backend\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3e975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that results from GPU and CPU are equivalent\n",
    "if gpu_available:\n",
    "    # The results should be very close but not exactly the same due to floating-point differences\n",
    "    print(f\"Maximum absolute difference: {np.max(np.abs(vis_gpu - vis_cpu))}\")\n",
    "    print(f\"Are GPU and CPU results close? {np.allclose(vis_gpu, vis_cpu, rtol=1e-5, atol=1e-7)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aeae35",
   "metadata": {},
   "source": [
    "## Benchmark Performance: GPU vs CPU\n",
    "\n",
    "Let's benchmark the performance difference between GPU and CPU backends with increasing number of sources. The GPU advantage typically becomes more apparent with larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4841d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_performance(nsides, ntimes=10, nfreqs=5):\n",
    "    \"\"\"Benchmark GPU vs CPU performance for different HEALPix nsides.\"\"\"\n",
    "    \n",
    "    # Shorter time and frequency arrays for benchmarking\n",
    "    short_freqs = np.linspace(100e6, 120e6, nfreqs)\n",
    "    short_times = Time(np.linspace(2459845, 2459845.02, ntimes), format='jd', scale='utc')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for nside in nsides:\n",
    "        nsource = hp.nside2npix(nside)\n",
    "        print(f\"Running benchmark with nside={nside}, nsource={nsource}\")\n",
    "        \n",
    "        # Create sky model\n",
    "        dec, ra = hp.pix2ang(nside, np.arange(nsource))\n",
    "        dec -= np.pi / 2\n",
    "        flux = np.random.uniform(0, 1, nsource)\n",
    "        alpha = np.ones(nsource) * -0.8\n",
    "        flux_allfreq = ((short_freqs[:, np.newaxis] / short_freqs[0]) ** alpha.T * flux.T).T\n",
    "        \n",
    "        # Time CPU simulation\n",
    "        t0 = time.time()\n",
    "        _ = fftvis.simulate_vis(\n",
    "            ants=antpos,\n",
    "            fluxes=flux_allfreq,\n",
    "            ra=ra,\n",
    "            dec=dec,\n",
    "            freqs=short_freqs,\n",
    "            times=short_times.jd,\n",
    "            telescope_loc=telescope_loc,\n",
    "            beam=beam,\n",
    "            polarized=False,\n",
    "            precision=2,\n",
    "            nprocesses=1,\n",
    "            baselines=baselines[:10],  # Use fewer baselines for speed\n",
    "            backend=\"cpu\"\n",
    "        )\n",
    "        cpu_time = time.time() - t0\n",
    "        \n",
    "        # Time GPU simulation\n",
    "        gpu_time = None\n",
    "        if gpu_available:\n",
    "            t0 = time.time()\n",
    "            _ = fftvis.simulate_vis(\n",
    "                ants=antpos,\n",
    "                fluxes=flux_allfreq,\n",
    "                ra=ra,\n",
    "                dec=dec,\n",
    "                freqs=short_freqs,\n",
    "                times=short_times.jd,\n",
    "                telescope_loc=telescope_loc,\n",
    "                beam=beam,\n",
    "                polarized=False,\n",
    "                precision=2,\n",
    "                nprocesses=1,\n",
    "                baselines=baselines[:10],  # Use fewer baselines for speed\n",
    "                backend=\"gpu\"\n",
    "            )\n",
    "            gpu_time = time.time() - t0\n",
    "            # Clear GPU memory\n",
    "            if 'cp' in globals():\n",
    "                cp.cuda.runtime.deviceSynchronize()\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "        \n",
    "        results.append((nside, nsource, cpu_time, gpu_time))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarks with increasing HEALPix nside values\n",
    "# Skip if GPU is not available\n",
    "if gpu_available:\n",
    "    benchmark_results = benchmark_performance([8, 16, 32, 64])\n",
    "else:\n",
    "    print(\"GPU not available. Skipping benchmarks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fff76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the benchmark results\n",
    "if gpu_available and 'benchmark_results' in locals():\n",
    "    nsides, nsources, cpu_times, gpu_times = zip(*benchmark_results)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Plot execution times\n",
    "    ax1.plot(nsources, cpu_times, 'o-', label='CPU')\n",
    "    ax1.plot(nsources, gpu_times, 's-', label='GPU')\n",
    "    ax1.set_xlabel('Number of Sources')\n",
    "    ax1.set_ylabel('Execution Time (s)')\n",
    "    ax1.set_title('Execution Time Comparison')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot speedup ratios\n",
    "    speedups = [cpu/gpu for cpu, gpu in zip(cpu_times, gpu_times)]\n",
    "    ax2.plot(nsources, speedups, 'o-')\n",
    "    ax2.set_xlabel('Number of Sources')\n",
    "    ax2.set_ylabel('Speedup (CPU time / GPU time)')\n",
    "    ax2.set_title('GPU Speedup Factor')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff08726",
   "metadata": {},
   "source": [
    "## Plot Visibility Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52804f31",
   "metadata": {},
   "source": [
    "We'll plot the visibility amplitude and phase from the GPU simulation, similar to what we did in the CPU tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a0e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU results if available, otherwise CPU results\n",
    "vis_to_plot = vis_gpu if gpu_available else vis_cpu\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 6))\n",
    "for bl_index, bl in enumerate(baselines[:3]):\n",
    "    axs[0].semilogy(freqs / 1e6, np.abs(vis_to_plot[:, 0, bl_index]))\n",
    "    axs[1].plot(freqs / 1e6, np.angle(vis_to_plot[:, 0, bl_index]), label=f\"b = {bl[0]}\")\n",
    "\n",
    "axs[1].legend()\n",
    "axs[0].set_xlabel('Frequency [MHz]')\n",
    "axs[1].set_xlabel('Frequency [MHz]')\n",
    "axs[0].set_ylabel('Amplitude [Jy]')\n",
    "axs[1].set_ylabel('Phase [rad]')\n",
    "axs[1].set_ylim(-np.pi * 1.1, np.pi * 1.1)\n",
    "axs[0].grid()\n",
    "axs[1].grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 6))\n",
    "for bl_index, bl in enumerate(baselines[:3]):\n",
    "    axs[0].semilogy(times.unix - times.unix[0], np.abs(vis_to_plot[0, :, bl_index]))\n",
    "    axs[1].plot(times.unix - times.unix[0], np.angle(vis_to_plot[0, :, bl_index]), label=f\"b = {bl[0]}\")\n",
    "\n",
    "axs[0].set_xlabel('Times [s]')\n",
    "axs[1].set_xlabel('Times [s]')\n",
    "axs[0].set_ylabel('Amplitude [Jy]')\n",
    "axs[1].set_ylabel('Phase [rad]')\n",
    "axs[1].set_ylim(-np.pi * 1.1, np.pi * 1.1)\n",
    "axs[0].grid()\n",
    "axs[1].grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b18612",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The GPU backend of `fftvis` provides a significant speedup compared to the CPU backend, especially for larger sky models with many sources. The main advantages are:\n",
    "\n",
    "1. Accelerated non-uniform FFT operations using `cufinufft`\n",
    "2. Parallel processing of source computations on the GPU\n",
    "3. Efficient beam interpolation using GPU-accelerated map coordinates\n",
    "\n",
    "When working with large simulations, the GPU backend is recommended if suitable hardware is available. For smaller simulations, the overhead of data transfer between CPU and GPU might reduce the performance advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab78282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up GPU memory if we used it\n",
    "if gpu_available and 'cp' in globals():\n",
    "    cp.cuda.runtime.deviceSynchronize()\n",
    "    cp.get_default_memory_pool().free_all_blocks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
