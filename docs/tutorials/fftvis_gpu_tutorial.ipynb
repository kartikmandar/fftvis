{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7221ef1",
   "metadata": {},
   "source": [
    "# Running `fftvis` with the GPU Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce8dc6",
   "metadata": {},
   "source": [
    "In this notebook, we'll demonstrate how to use `fftvis` with GPU acceleration to simulate visibilities. The GPU backend can significantly accelerate simulations, especially for large catalogs of point sources or extended observations with many frequencies and time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0836a520",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "__Note__\n",
    "\n",
    "This tutorial requires a CUDA-capable GPU and the `cupy` package installed. If you don't have a compatible GPU, you can use the CPU backend instead.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d021b5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "__Warning__\n",
    "\n",
    "Before running this tutorial, make sure you have installed `fftvis` with GPU support. You can check if your GPU is properly configured by running a simple test with `cupy`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd48302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy version: 13.4.1\n",
      "CUDA version: 11080\n",
      "Available GPU(s): 1\n",
      "  Device 0: Quadro P600, Memory: 2.08 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "try:\n",
    "    import cupy as cp\n",
    "    print(f\"CuPy version: {cp.__version__}\")\n",
    "    print(f\"CUDA version: {cp.cuda.runtime.runtimeGetVersion()}\")\n",
    "    print(f\"Available GPU(s): {cp.cuda.runtime.getDeviceCount()}\")\n",
    "    for i in range(cp.cuda.runtime.getDeviceCount()):\n",
    "        dev = cp.cuda.Device(i)\n",
    "        props = cp.cuda.runtime.getDeviceProperties(i)\n",
    "        print(f\"  Device {i}: {props['name'].decode()}, Memory: {props['totalGlobalMem']/1e9:.2f} GB\")\n",
    "    gpu_available = True\n",
    "except ImportError:\n",
    "    print(\"CuPy is not installed. Please install it to use the GPU backend.\")\n",
    "    gpu_available = False\n",
    "except cp.cuda.runtime.CUDARuntimeError:\n",
    "    print(\"CUDA runtime error: No CUDA-capable device is detected or CUDA driver is not installed properly.\")\n",
    "    gpu_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac710755",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libcublas.so.11: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# HERA-stack imports\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfftvis\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhera_sim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mantpos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hex_array\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyuvdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtelescopes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Telescope\n",
      "File \u001b[0;32m~/fftvis/src/fftvis/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"FFT-based visibility simulator.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Import key components for beams\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeamEvaluator\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpu\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpu_beams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CPUBeamEvaluator\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_beam_evaluator\n",
      "File \u001b[0;32m~/fftvis/src/fftvis/core/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Core functionality for fftvis.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeamEvaluator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimulationEngine, default_accuracy_dict\n",
      "File \u001b[0;32m~/fftvis/src/fftvis/core/beams.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Import the matvis base class\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeamInterpolator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBeamEvaluator\u001b[39;00m(BeamInterpolator):\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Abstract base class for beam evaluation that inherits from matvis.BeamInterpolator.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    This class defines the interface for evaluating beams across different implementations\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    (CPU, GPU).\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/matvis-env/lib/python3.11/site-packages/matvis/__init__.py:25\u001b[0m\n\u001b[1;32m     21\u001b[0m     HAVE_GPU \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cpu\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simulate_vis\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m HAVE_GPU:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gpu\n",
      "File \u001b[0;32m~/anaconda3/envs/matvis-env/lib/python3.11/site-packages/matvis/wrapper.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prepare_beam_unpolarized\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m HAVE_GPU:\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gpu\n\u001b[1;32m     21\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimulate_vis\u001b[39m(\n\u001b[1;32m     25\u001b[0m     ants: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[1;32m     26\u001b[0m     fluxes: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbackend_kwargs,\n\u001b[1;32m     42\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/matvis-env/lib/python3.11/site-packages/matvis/gpu/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"GPU-accelerated matvis implementation.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coords\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simulate\n",
      "File \u001b[0;32m~/anaconda3/envs/matvis-env/lib/python3.11/site-packages/matvis/gpu/gpu.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpu\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simulate \u001b[38;5;28;01mas\u001b[39;00m simcpu\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m beams\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m matprod \u001b[38;5;28;01mas\u001b[39;00m mp\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcp\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/matvis-env/lib/python3.11/site-packages/matvis/gpu/matprod.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatprod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatProd\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cublas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m complex_matmul, zdotz\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGPUMatMul\u001b[39;00m(MatProd):\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Use cupy.gemm to perform the source-summing operation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/matvis-env/lib/python3.11/site-packages/matvis/gpu/_cublas.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcupy_backends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cublas\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzdotz\u001b[39m(a, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m):\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Computes a.conj() @ a.T.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: libcublas.so.11: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "from astropy.time import Time\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# HERA-stack imports\n",
    "import fftvis\n",
    "from hera_sim.antpos import hex_array\n",
    "from pyuvdata.telescopes import Telescope\n",
    "from pyuvdata.analytic_beam import AiryBeam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e479a59",
   "metadata": {},
   "source": [
    "## Setup Telescope / Observation Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cef897",
   "metadata": {},
   "source": [
    "We'll set up the same observation parameters as in the CPU backend tutorial for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9baa4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define antenna array positions\n",
    "antpos = hex_array(3, split_core=True, outriggers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15234c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define antenna beam using pyuvdata.analytic_beam.AiryBeam with a dish size of 14 meters\n",
    "beam = AiryBeam(diameter=14.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0a06a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of frequencies in units of Hz\n",
    "nfreqs = 20\n",
    "freqs = np.linspace(100e6, 120e6, nfreqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42b9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of times with an astropy time.Time object\n",
    "ntimes = 30\n",
    "times = Time(np.linspace(2459845, 2459845.05, ntimes), format='jd', scale='utc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcd734be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the telescope location\n",
    "telescope_loc = Telescope.from_known_telescopes('hera').location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0540d40",
   "metadata": {},
   "source": [
    "## Setup Sky Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "866079fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a sky model using HEALPix\n",
    "nside = 64\n",
    "nsource = hp.nside2npix(nside)\n",
    "\n",
    "# Get HEALPix pixel coordinates\n",
    "dec, ra = hp.pix2ang(nside, np.arange(nsource))\n",
    "dec -= np.pi / 2  # Convert from co-latitude to declination\n",
    "\n",
    "# Define the flux of the sources as a function of frequency\n",
    "flux = np.random.uniform(0, 1, nsource)                # flux of each source at 100MHz (in Jy)\n",
    "alpha = np.ones(nsource) * -0.8                        # spectral index of each source\n",
    "\n",
    "# Now get the (Nsource, Nfreq) array of the flux of each source at each frequency\n",
    "flux_allfreq = ((freqs[:, np.newaxis] / freqs[0]) ** alpha.T * flux.T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a45d711",
   "metadata": {},
   "source": [
    "## Run `fftvis` with GPU Backend\n",
    "\n",
    "Unlike the CPU backend which uses `finufft` for non-uniform FFT operations, the GPU backend in `fftvis` uses `cufinufft` through CuPy. This allows for significant speedups, especially with large numbers of sources. \n",
    "\n",
    "To use the GPU backend, we simply specify `backend=\"gpu\"` in the `simulate_vis` function call. All other parameters remain the same as in the CPU version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acd21e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subset of baselines we're interested in for simulating\n",
    "baselines = [(i, j) for i in range(len(antpos)) for j in range(len(antpos))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bfb9b0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "GPU simulation not yet implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[0;32m~/fftvis/src/fftvis/wrapper.py:211\u001b[0m, in \u001b[0;36msimulate_vis\u001b[0;34m(ants, fluxes, ra, dec, freqs, times, beam, telescope_loc, baselines, precision, polarized, eps, beam_spline_opts, use_feed, flat_array_tol, interpolation_function, nprocesses, nthreads, coord_method, coord_method_params, force_use_ray, trace_mem, backend)\u001b[0m\n\u001b[1;32m    208\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_simulation_engine(backend\u001b[38;5;241m=\u001b[39mbackend)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Run the simulation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mants\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfluxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfluxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtelescope_loc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtelescope_loc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolarized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolarized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam_spline_opts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_spline_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_array_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_array_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolation_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnprocesses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnprocesses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoord_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoord_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoord_method_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoord_method_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_use_ray\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_use_ray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrace_mem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_mem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fftvis/src/fftvis/gpu/gpu_simulate.py:60\u001b[0m, in \u001b[0;36mGPUSimulationEngine.simulate\u001b[0;34m(self, ants, freqs, fluxes, beam, ra, dec, times, telescope_loc, baselines, precision, polarized, eps, beam_spline_opts, flat_array_tol, interpolation_function, nprocesses, nthreads, coord_method, coord_method_params, force_use_ray, trace_mem, enable_memory_monitor)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimulate\u001b[39m(\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     25\u001b[0m     ants: \u001b[38;5;28mdict\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     enable_memory_monitor: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    Simulate visibilities using GPU implementation.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m        GPU simulation is not yet implemented.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU simulation not yet implemented\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: GPU simulation not yet implemented"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Simulate visibilities using the GPU backend\n",
    "if gpu_available:\n",
    "    vis_gpu = fftvis.simulate_vis(\n",
    "        ants=antpos,\n",
    "        fluxes=flux_allfreq,\n",
    "        ra=ra,\n",
    "        dec=dec,\n",
    "        freqs=freqs,\n",
    "        times=times.jd,\n",
    "        telescope_loc=telescope_loc,\n",
    "        beam=beam,\n",
    "        polarized=False,\n",
    "        precision=2,\n",
    "        nprocesses=1,  # Use single process for GPU simulation\n",
    "        baselines=baselines,\n",
    "        backend=\"gpu\"  # Use GPU backend\n",
    "    )\n",
    "else:\n",
    "    print(\"GPU not available. Skipping GPU simulation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9bfea0",
   "metadata": {},
   "source": [
    "## Compare GPU and CPU Backends\n",
    "\n",
    "Let's run the same simulation with the CPU backend for comparison. We expect the results to be nearly identical, with the main difference being the computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da580ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Simulate visibilities using the CPU backend\n",
    "vis_cpu = fftvis.simulate_vis(\n",
    "    ants=antpos,\n",
    "    fluxes=flux_allfreq,\n",
    "    ra=ra,\n",
    "    dec=dec,\n",
    "    freqs=freqs,\n",
    "    times=times.jd,\n",
    "    telescope_loc=telescope_loc,\n",
    "    beam=beam,\n",
    "    polarized=False,\n",
    "    precision=2,\n",
    "    nprocesses=1,\n",
    "    baselines=baselines,\n",
    "    backend=\"cpu\"  # Use CPU backend\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3e975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that results from GPU and CPU are equivalent\n",
    "if gpu_available:\n",
    "    # The results should be very close but not exactly the same due to floating-point differences\n",
    "    print(f\"Maximum absolute difference: {np.max(np.abs(vis_gpu - vis_cpu))}\")\n",
    "    print(f\"Are GPU and CPU results close? {np.allclose(vis_gpu, vis_cpu, rtol=1e-5, atol=1e-7)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aeae35",
   "metadata": {},
   "source": [
    "## Benchmark Performance: GPU vs CPU\n",
    "\n",
    "Let's benchmark the performance difference between GPU and CPU backends with increasing number of sources. The GPU advantage typically becomes more apparent with larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4841d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_performance(nsides, ntimes=10, nfreqs=5):\n",
    "    \"\"\"Benchmark GPU vs CPU performance for different HEALPix nsides.\"\"\"\n",
    "    \n",
    "    # Shorter time and frequency arrays for benchmarking\n",
    "    short_freqs = np.linspace(100e6, 120e6, nfreqs)\n",
    "    short_times = Time(np.linspace(2459845, 2459845.02, ntimes), format='jd', scale='utc')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for nside in nsides:\n",
    "        nsource = hp.nside2npix(nside)\n",
    "        print(f\"Running benchmark with nside={nside}, nsource={nsource}\")\n",
    "        \n",
    "        # Create sky model\n",
    "        dec, ra = hp.pix2ang(nside, np.arange(nsource))\n",
    "        dec -= np.pi / 2\n",
    "        flux = np.random.uniform(0, 1, nsource)\n",
    "        alpha = np.ones(nsource) * -0.8\n",
    "        flux_allfreq = ((short_freqs[:, np.newaxis] / short_freqs[0]) ** alpha.T * flux.T).T\n",
    "        \n",
    "        # Time CPU simulation\n",
    "        t0 = time.time()\n",
    "        _ = fftvis.simulate_vis(\n",
    "            ants=antpos,\n",
    "            fluxes=flux_allfreq,\n",
    "            ra=ra,\n",
    "            dec=dec,\n",
    "            freqs=short_freqs,\n",
    "            times=short_times.jd,\n",
    "            telescope_loc=telescope_loc,\n",
    "            beam=beam,\n",
    "            polarized=False,\n",
    "            precision=2,\n",
    "            nprocesses=1,\n",
    "            baselines=baselines[:10],  # Use fewer baselines for speed\n",
    "            backend=\"cpu\"\n",
    "        )\n",
    "        cpu_time = time.time() - t0\n",
    "        \n",
    "        # Time GPU simulation\n",
    "        gpu_time = None\n",
    "        if gpu_available:\n",
    "            t0 = time.time()\n",
    "            _ = fftvis.simulate_vis(\n",
    "                ants=antpos,\n",
    "                fluxes=flux_allfreq,\n",
    "                ra=ra,\n",
    "                dec=dec,\n",
    "                freqs=short_freqs,\n",
    "                times=short_times.jd,\n",
    "                telescope_loc=telescope_loc,\n",
    "                beam=beam,\n",
    "                polarized=False,\n",
    "                precision=2,\n",
    "                nprocesses=1,\n",
    "                baselines=baselines[:10],  # Use fewer baselines for speed\n",
    "                backend=\"gpu\"\n",
    "            )\n",
    "            gpu_time = time.time() - t0\n",
    "            # Clear GPU memory\n",
    "            if 'cp' in globals():\n",
    "                cp.cuda.runtime.deviceSynchronize()\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "        \n",
    "        results.append((nside, nsource, cpu_time, gpu_time))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarks with increasing HEALPix nside values\n",
    "# Skip if GPU is not available\n",
    "if gpu_available:\n",
    "    benchmark_results = benchmark_performance([8, 16, 32, 64])\n",
    "else:\n",
    "    print(\"GPU not available. Skipping benchmarks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fff76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the benchmark results\n",
    "if gpu_available and 'benchmark_results' in locals():\n",
    "    nsides, nsources, cpu_times, gpu_times = zip(*benchmark_results)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Plot execution times\n",
    "    ax1.plot(nsources, cpu_times, 'o-', label='CPU')\n",
    "    ax1.plot(nsources, gpu_times, 's-', label='GPU')\n",
    "    ax1.set_xlabel('Number of Sources')\n",
    "    ax1.set_ylabel('Execution Time (s)')\n",
    "    ax1.set_title('Execution Time Comparison')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot speedup ratios\n",
    "    speedups = [cpu/gpu for cpu, gpu in zip(cpu_times, gpu_times)]\n",
    "    ax2.plot(nsources, speedups, 'o-')\n",
    "    ax2.set_xlabel('Number of Sources')\n",
    "    ax2.set_ylabel('Speedup (CPU time / GPU time)')\n",
    "    ax2.set_title('GPU Speedup Factor')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff08726",
   "metadata": {},
   "source": [
    "## Plot Visibility Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52804f31",
   "metadata": {},
   "source": [
    "We'll plot the visibility amplitude and phase from the GPU simulation, similar to what we did in the CPU tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a0e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU results if available, otherwise CPU results\n",
    "vis_to_plot = vis_gpu if gpu_available else vis_cpu\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 6))\n",
    "for bl_index, bl in enumerate(baselines[:3]):\n",
    "    axs[0].semilogy(freqs / 1e6, np.abs(vis_to_plot[:, 0, bl_index]))\n",
    "    axs[1].plot(freqs / 1e6, np.angle(vis_to_plot[:, 0, bl_index]), label=f\"b = {bl[0]}\")\n",
    "\n",
    "axs[1].legend()\n",
    "axs[0].set_xlabel('Frequency [MHz]')\n",
    "axs[1].set_xlabel('Frequency [MHz]')\n",
    "axs[0].set_ylabel('Amplitude [Jy]')\n",
    "axs[1].set_ylabel('Phase [rad]')\n",
    "axs[1].set_ylim(-np.pi * 1.1, np.pi * 1.1)\n",
    "axs[0].grid()\n",
    "axs[1].grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 6))\n",
    "for bl_index, bl in enumerate(baselines[:3]):\n",
    "    axs[0].semilogy(times.unix - times.unix[0], np.abs(vis_to_plot[0, :, bl_index]))\n",
    "    axs[1].plot(times.unix - times.unix[0], np.angle(vis_to_plot[0, :, bl_index]), label=f\"b = {bl[0]}\")\n",
    "\n",
    "axs[0].set_xlabel('Times [s]')\n",
    "axs[1].set_xlabel('Times [s]')\n",
    "axs[0].set_ylabel('Amplitude [Jy]')\n",
    "axs[1].set_ylabel('Phase [rad]')\n",
    "axs[1].set_ylim(-np.pi * 1.1, np.pi * 1.1)\n",
    "axs[0].grid()\n",
    "axs[1].grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b18612",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The GPU backend of `fftvis` provides a significant speedup compared to the CPU backend, especially for larger sky models with many sources. The main advantages are:\n",
    "\n",
    "1. Accelerated non-uniform FFT operations using `cufinufft`\n",
    "2. Parallel processing of source computations on the GPU\n",
    "3. Efficient beam interpolation using GPU-accelerated map coordinates\n",
    "\n",
    "When working with large simulations, the GPU backend is recommended if suitable hardware is available. For smaller simulations, the overhead of data transfer between CPU and GPU might reduce the performance advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab78282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up GPU memory if we used it\n",
    "if gpu_available and 'cp' in globals():\n",
    "    cp.cuda.runtime.deviceSynchronize()\n",
    "    cp.get_default_memory_pool().free_all_blocks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
